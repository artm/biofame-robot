[*] open / close mc when button's pressed
[*] press the button on start
[*] close mc on exit

* * *

need "MC_CHECK_RESULT" and a generic system of throwing, logging and catching exceptions.

* * *

displays:
[x] lcnt
[x] speed
[x] input ticks

controls:
[x] default axis parameters
[x] stop button
[x] go cw/ccw buttons
[x] output ticks

* * *

had to prepare motorc like:

PATH=/c/MinGW/bin/:/c/Program\ Files/CMake\ 2.8/bin MAX_SDK_ROOT=~/src/sdk/MaxSDK-5.1.1/ cmake ..
/motorc -G "CodeBlocks - MinGW Makefiles" -DBOOST_ROOT=~/src/sdk/boost_1_44_0/

after which could import the project into Qt Creator

* * *

[x] an object encapsulating a motor
    all communication with the motor goes via this object
    it also takes care that state is displayed by the GUI
[x] engage motors on open
    [x] need a way to send outputs to motors
    [x] need to display output states...
    [x] need to connect button group events, not what I have now
[x] without any feedback send stop and continuous motion commands
[x] feedback: want to pick up the axis parameters...
[x] parameter settage
[x] save axis parameters to eprom just before closing...

[x] poll:
    [x] counter
    [x] speed
    [x] inputs

no separate thread yet, just a timer that polls everything important for every motor.

[x] circular calibration
    [x] panic button
    [x] calibrate button
    [x] axis knows how to calibrate itself
    [x] input changes send signals or events
    [ ] calc and show pulse <=> degrees
    [ ] inv and offset controls for circular axes
    [ ] posing API in degrees

[ ] face detection / tracking
    [x] video input
    [ ] video preprocessing:
        [x] deinterlace (fast scale down by 2x2)
        [x] greyscale
        [ ] normalize
    [x] video display (fast scale to 320 width)
    [x] detect faces and display detection parameters

* * *

pose estimation. this is only relevant to calibrated axes - for now the two 360 degree circular ones.

[x] calibration: assume initial pose is known (0)
    [x] when first hit the trigger remember distance from 0 to trigger and clear pos counter
    [x] when hit the trigger second time remember the circle length
    [x] save offset and length to the settings
[x] maintaining the counter
    [x] maintain the motor direction
    [x] when moving in positive direction and the trigger goes 1-0 spring to 0
    [x] when moving in negative direction and the trigger goes 0-1 spring to circle length
[x] normal start up
    [x] load axes parameters
    [x] go until hit the trigger, from here on pose can be estimated
    [x] maintain the direction of every motion
[x] convert pos to angle (pose estimation)

* * *

[x] save/load setings
    [x] video processing
    [x] robot motion
    [x] robot calibration values
    [x] verilook

* * *

Switched to self built videoInput library. It is possible to load into Qt creator and
build with MinGW, just had to add "C:\MinGW\bin" to PATH in project's environment.

Similarly: to make the executable start no matter what need to make sure all .dll's it links
can be found through PATH.

* * *

Today (20 april) wheels logic:

[x] make body emit its estimated angle (anything with circle parameters calibrated)
[x] wheels slot trackAxisDirection( angle ), which should set up track force
[x] make wheels react on trackAxisDirection only when in seek behavior

[x] axis tracking should use angle instead of the counter
[x] face tracking force should go from -1 to 1
[x] crash on exit (only on the robot)
[x] body resets calibration on seek???

[x] verilook setup
    [x] controls in the GUI
    [x] load/save

this prompts for a Behavior concept:

1. composite state for each axis
2. particular combination of signal-slot connections active during particular states

* * *

[ ] point to point motion doesn't work for wheels. consider an alternative.

* * *

[ ] init motors at startup
    - need to make sure it is called at the rigth moment

[x] hide unused parameters from the gui
[ ] some explanations in the gui
[x] force indicator for each axis

[ ] wander behavior
    [ ] describe in plain English
    [ ] implement
    [ ] switches to seek if detects a face
    [ ] seek behavior switches to wander if lost face for a long time
    [ ] rename "seek" to "approach" and "wander" to "seek"

[ ] leave behavior
    - move away for some time (say 20 sec) then switch to wander

[ ] video + graphics on a QGraphicsView.
    [ ] May be a new QGraphicsItem for the video and its children in pixel coordinates...

[ ] Adjust robot's environment so Qt sdk is in PATH

* * *

It's unclear where the continuous motion logic breaks. Often the axis won't start at all -
is it due to bad self-consciousness (not knowing if the motor is running, breaking or stopped),
bad face detection (sometimes it seems less reliable) or bad settings (too high or too low
speeds - implement better checks / limits).

In fact desired speed should be force*maxspeed. This time it'll never be too high and configuring it
will be easier. The default motor parameters should be saved/restored together with the rest, or at
least dv should be forced to the one in GUI before storing.

Need more introspection tools - display current states etc per axis and may be on the same
screen. Also would be nice to save a stream:

Notes from paper...

[.] camera angle tracking is broken. find out why, something went wrong when I switched from Lcnt to
    angle tracking
    - apparently the problem was with not normalizing the angle difference

[.] face size should modulate face tracking force - the further from face, the smaller the face, the smaller
    the force should be
    [.] don't forget to save/load new parameters

[ ] after face has disappeared the force should persist for some time then become 0 and emit "lostface()"

[.] Body slips a lot but rarely comes by the trigger. This leads to wheels going the wrong way and stopping at
    the wrong moment. Possible solution is lower acceleration for the body which may lead to bad behavior.
    XXX just make sure body's acceleration value is low enough.

[ ] Motor control and face detection begin to conflict (especially with small steps motions), should really
    only use continuous motion mostly.

[x] Need a screen grabber + all relevant tracking variables displayed on a single screen + current time displayed
    and log with timestamps.
    [x] install/setup screen grabber
        - MS Expression Encoder 4 appears to support screen capture, downloading
    [x] display the timestamp under the video...
    [x] Make sure tracking page opens by default
    [x] Give them titles
    [x] Log with timestamps

[x] Don't initialize on motor controller open -> otherwise it's impossible to calibrate

[ ] body stops tracking camera angle once it has reached desire
    - has probably to do with "driveFinished()" signal not arriving. or not?
    - apparently not. here is the automaton:
        s1->addTransition(this, SIGNAL(haveForce()), s2);
        s2->addTransition(this, SIGNAL(driveFinished()), s1 );
        connect(s1, SIGNAL(entered()), this, SLOT(checkForce()));
        connect(s2, SIGNAL(entered()), this, SLOT(moveToForce()));
    ....
    what's wrong with this picture? if s2 misses "driveFinished" it will never go to haveForce and hence never
    start again.  this is not very robust. instead, should be like:

    1. force arrives
    2. if (tracking && ! moving && force is > threshold) - move

    the problem with this approach is that when camera doesn't move it's new angle isn't sent to the body.
    so, force isn't arriving constantly. well, may be it should.

    fixed for the body didn't fix it for the camera: as soon as the face is lost it stops sending. so really, we
    should know when we have stopped motion and check if we need to move then. that is: track(m_trackForce) upon
    stop.

[ ] on exit save lcnts and on open - restore them. this will make reinitialisation unnecessary when developing.

[ ] motor is confused about its MotionState...
    don't matter now with continuous motion.

* * *

[ ] Have to implement a higher level automaton doing the search / approach

1. search
1.1. camera: oscilate
1.2. arm (vertical): oscilate
1.3. body: go 90 for some time then turn -90 for some time etc
1.4. wheels: follow the body

2. approach
2.1. camera: follow face within some range (say +/- 60)
2.2. body: try to keep camera at 0
2.3. arm: follow face within the range
2.4. wheels: follow the body

3. switching between the two
3.1. start in search
3.2. faceDetected signal should move from search to approach
3.3. each faceDetected restarts loseTimer
3.4. loseTimer's timeout moves from approach to search

[x] force->speed should use max configured speed as force 1.0

* * *

better tracking...

[x] universal face detector (use verilook or opencv, which ever is available)
    [x] single class to handle both (or either)
    [x] convert incoming image to cv::Mat
    [x] detect faces
    [x] convert results to QRect list

[x] CAMSHIFT tracker
    - based on: http://www.cognotics.com/opencv/servo_2007_series/part_3/index.html
    [x] state machine:
        (a) searching for faces
            (a) -> found face -> (b)
        (b) track face (by color)
            (b) -> lost face -> (a)
        ( ) add some inertia (lost face but remember in which direction it went - continue
            going there for some time
        --- this is a robot behavior, not tracker's state
  [x] add smin/vmin/vmax mask
  [x] add "force reset to detection phase" button and API
  [x] calculate and display avg probability inside the tracked area
  [x] use that to trigger re-targeting
  [x] save/load smin/vmin/vmax
  [x] make the retrack threshold configurable / saveable
  [x] display probability image

* * *

* compound seek behavior

* tracking state
need a method to setup tracking and another one to dismantle
setup (init, on SIGNAL(enter()):
[x] feed camera angle to body tracker
[x] feed body angle to wheels tracker

instead of connect/disconnect the tracking data has to be stored in the shell and passed in Tick()'s:
[x] store tracking data: force vector, face size, last seen

* * *

[x] random walk: two states - decision and walk.
    decision sets up the motor and schedules stop.
    walk does nothing and returns to decision upon SIGNAL(driveFinished())

* * *

Make states report themselves using slot that prints its sender.

* * *

more complex state machine:


Instead of relying on signal slot connections should send appropriate values to slots depending on the robot state.
Individual axes could be state machines or not, but the idea is that there is an "advance" method (like "poll()" is now) which does state specifc things.

[ ] Force saturation
[x] Stop criterium (high level state?)
[x] GOTCHA state continues for N sec
    [x] gotcha criterion and signal: the best place is notifyOfFace() helper - it sends either faceDetected or gotcha.
    [x] gotcha state enter (no tick - wait for timeout)
    [ ] gotcha size in GUI and config file
[ ] Sounds at state changes
[ ] vertical axis logic
[ ] speed = F(face_size) for all axes
[ ] separate thread for video processing (so polling the motor is faster)
[ ] setSpeedToMax() in appropriate places
    [x] when starting some seek states
    [ ] upon init
    [ ] upon calib
    [ ] on manual control
